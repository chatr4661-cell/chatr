import { supabase } from "@/integrations/supabase/client";
import type { RealtimeChannel } from "@supabase/supabase-js";
import { classifyNetwork, NetworkQuality, onNetworkChange } from "./networkClassification";
import { getCallPreset, getWebRTCConfig, getMediaConstraints, applyBitrateLimits, CallPreset } from "./indiaCallPresets";
import { createICEMonitor, ICEMonitorState } from "./iceConnectionMonitor";

type CallState = 'connecting' | 'connected' | 'failed' | 'ended';
type SignalType = 'offer' | 'answer' | 'ice-candidate' | 'video-request' | 'video-accept' | 'video-reject' | 'video-enable';

interface Signal {
  type: SignalType;
  data: any;
  from: string;
}

// Video upgrade callback type
export type VideoUpgradeCallback = (fromUserId: string) => void;

// GLOBAL: Prevent duplicate WebRTC instances for same call
const activeCallInstances = new Map<string, SimpleWebRTCCall>();
// CRITICAL: Prevent race conditions during instance creation
const creationLocks = new Set<string>();

// Get existing instance (TRUE singleton pattern)
export function getExistingCall(callId: string): SimpleWebRTCCall | undefined {
  return activeCallInstances.get(callId);
}

// Check if instance exists or is being created
export function hasActiveCall(callId: string): boolean {
  return activeCallInstances.has(callId) || creationLocks.has(callId);
}

// Clear existing instance for a call
export function clearCallInstance(callId: string): void {
  const existing = activeCallInstances.get(callId);
  if (existing) {
    existing.end();
  }
  activeCallInstances.delete(callId);
  creationLocks.delete(callId);
}

/**
 * SimpleWebRTCCall - Robust, Fast WebRTC Implementation
 * 
 * Key improvements:
 * - TRUE SINGLETON per call ID (factory pattern with creation lock)
 * - Faster ICE gathering with aggressive candidate pool
 * - Single offer per connection attempt (no spam)
 * - Proper answer timeout handling
 * - Graceful media fallback
 * - Clear state management
 */
export class SimpleWebRTCCall {
  private pc: RTCPeerConnection | null = null;
  private localStream: MediaStream | null = null;
  private signalChannel: RealtimeChannel | null = null;
  private callState: CallState = 'connecting';
  private eventHandlers: Map<string, Function[]> = new Map();
  private pendingIceCandidates: RTCIceCandidate[] = [];
  private hasReceivedAnswer: boolean = false;
  private connectionTimeout: NodeJS.Timeout | null = null;
  private offerSent: boolean = false;
  private answerSent: boolean = false;
  private processedSignalIds: Set<string> = new Set();
  private started: boolean = false;
  private instanceId: string; // For debugging
  
  // India-first: Network-aware configuration
  private networkQuality: NetworkQuality = 'HOSTILE'; // Default to worst-case
  private callPreset: CallPreset | null = null;
  private iceMonitor: (ICEMonitorState & { cleanup: () => void }) | null = null;
  private networkChangeCleanup: (() => void) | null = null;

  // Factory method - use this instead of constructor
  static create(
    callId: string,
    partnerId: string,
    isVideo: boolean,
    isInitiator: boolean,
    userId: string,
    initialLocalStream: MediaStream | null = null
  ): SimpleWebRTCCall {
    // STRICT SINGLETON CHECK 1: Return existing instance
    const existing = activeCallInstances.get(callId);
    if (existing) {
      console.log('‚ö†Ô∏è [WebRTC] Returning existing instance for call:', callId.slice(0, 8));
      return existing;
    }
    
    // STRICT SINGLETON CHECK 2: Block if creation in progress
    if (creationLocks.has(callId)) {
      console.log('üîí [WebRTC] Creation in progress, waiting for existing instance:', callId.slice(0, 8));
      // Return existing if it appeared during the lock
      const waitingInstance = activeCallInstances.get(callId);
      if (waitingInstance) return waitingInstance;
      // This shouldn't happen, but create anyway with warning
      console.warn('‚ö†Ô∏è [WebRTC] Lock exists but no instance - creating anyway');
    }
    
    // Acquire creation lock BEFORE creating instance
    creationLocks.add(callId);
    console.log('üîê [WebRTC] Acquired creation lock for:', callId.slice(0, 8));
    
    const instance = new SimpleWebRTCCall(callId, partnerId, isVideo, isInitiator, userId, initialLocalStream);
    activeCallInstances.set(callId, instance);
    
    // Release lock (instance is now in map)
    creationLocks.delete(callId);
    
    return instance;
  }

  private constructor(
    private callId: string,
    private partnerId: string,
    private isVideo: boolean,
    private isInitiator: boolean,
    private userId: string,
    initialLocalStream: MediaStream | null = null
  ) {
    // Generate unique instance ID for debugging duplicate detection
    this.instanceId = `${callId.slice(0, 8)}-${Date.now().toString(36)}`;
    
    if (initialLocalStream) {
      this.localStream = initialLocalStream;
      console.log('üé§ [WebRTC] Using pre-acquired media stream');
    }
    console.log(`üé¨ [WebRTC] Init [${this.instanceId}]:`, { isVideo, isInitiator, userId: userId.slice(0, 8) });
    
    // India-first: Classify network immediately
    this.networkQuality = classifyNetwork();
    this.callPreset = getCallPreset(this.networkQuality, isVideo);
    console.log(`üáÆüá≥ [WebRTC] India-first preset: ${this.callPreset.name} (network: ${this.networkQuality})`);
  }

  on(event: string, handler: Function) {
    if (!this.eventHandlers.has(event)) {
      this.eventHandlers.set(event, []);
    }
    this.eventHandlers.get(event)!.push(handler);
  }

  private emit(event: string, ...args: any[]) {
    const handlers = this.eventHandlers.get(event);
    if (handlers) {
      handlers.forEach(handler => handler(...args));
    }
  }

  async start() {
    // Prevent double-start
    if (this.started || this.pc) {
      console.log('‚ö†Ô∏è [WebRTC] Already started, skipping');
      return;
    }
    this.started = true;
    const startTime = Date.now();
    
    try {
      console.log('üöÄ [WebRTC] FAST START - targeting <2s connection...');
      
      // PARALLEL: Create peer connection and subscribe to signals simultaneously
      // This saves ~200-300ms by not waiting sequentially
      const [_, __] = await Promise.all([
        this.createPeerConnection(),
        this.subscribeToSignals()
      ]);

      // Get media (may already be provided)
      if (!this.localStream) {
        await this.acquireMedia();
      } else {
        this.emit('localStream', this.localStream);
      }

      // Add tracks to peer connection
      if (this.localStream && this.pc) {
        this.localStream.getTracks().forEach(track => {
          console.log('‚ûï [WebRTC] Adding track:', track.kind);
          this.pc!.addTrack(track, this.localStream!);
        });
      }

      // Fetch past signals (for late joiners)
      await this.fetchPastSignals();

      // Create offer IMMEDIATELY (no delay - receiver subscription is already active)
      if (this.isInitiator && !this.offerSent) {
        await this.createAndSendOffer();
      }

      // Set connection timeout
      this.startConnectionTimeout();

      console.log(`‚úÖ [WebRTC] Setup complete in ${Date.now() - startTime}ms`);
    } catch (error: any) {
      console.error('‚ùå [WebRTC] Setup failed:', error);
      this.callState = 'failed';
      this.emit('failed', error);
    }
  }

  private async acquireMedia() {
    try {
      // Release existing streams first
      if (this.localStream) {
        this.localStream.getTracks().forEach(t => t.stop());
        this.localStream = null;
        await this.delay(100);
      }

      // AUTOMATIC NOISE CANCELLATION - Studio-grade audio with all enhancements enabled silently
      const audioConstraints: MediaTrackConstraints = {
        echoCancellation: { ideal: true },
        noiseSuppression: { ideal: true },
        autoGainControl: { ideal: true },
        sampleRate: { ideal: 48000 },
        sampleSize: { ideal: 16 },
        channelCount: { ideal: 1 },
        // Chrome/Edge advanced constraints for superior noise cancellation
        // @ts-ignore - experimental constraints
        googEchoCancellation: true,
        // @ts-ignore
        googAutoGainControl: true,
        // @ts-ignore
        googNoiseSuppression: true,
        // @ts-ignore
        googNoiseReduction: true,
        // @ts-ignore
        googHighpassFilter: true,
        // @ts-ignore
        googTypingNoiseDetection: true,
        // @ts-ignore
        googExperimentalNoiseSuppression: true,
        // @ts-ignore
        googBeamforming: true,
      };

      // ULTRA HD VIDEO with progressive fallback
      const constraints: MediaStreamConstraints = {
        audio: audioConstraints,
        video: this.isVideo ? {
          width: { ideal: 3840, min: 640 },
          height: { ideal: 2160, min: 480 },
          frameRate: { ideal: 60, min: 15 },
          facingMode: 'user',
          aspectRatio: { ideal: 16/9 },
        } : false
      };

      console.log('üé¨ [WebRTC] Requesting ULTRA HD media with AUTO NOISE CANCELLATION...');
      const startTime = Date.now();
      
      // Progressive fallback: 4K ‚Üí 1080p60 ‚Üí 1080p30 ‚Üí 720p ‚Üí 480p ‚Üí minimal
      const videoProfiles = this.isVideo ? [
        { width: 3840, height: 2160, fps: 60, label: '4K@60fps' },
        { width: 1920, height: 1080, fps: 60, label: '1080p@60fps' },
        { width: 1920, height: 1080, fps: 30, label: '1080p@30fps' },
        { width: 1280, height: 720, fps: 30, label: '720p@30fps' },
        { width: 640, height: 480, fps: 24, label: '480p@24fps' },
        { width: 320, height: 240, fps: 15, label: '240p@15fps' }, // Ultra-low bandwidth
      ] : [];
      
      let acquired = false;
      
      for (const profile of videoProfiles) {
        if (acquired) break;
        try {
          const profileConstraints: MediaStreamConstraints = {
            audio: audioConstraints,
            video: {
              width: { ideal: profile.width, min: 320 },
              height: { ideal: profile.height, min: 240 },
              frameRate: { ideal: profile.fps, min: 10 },
              facingMode: 'user',
            }
          };
          this.localStream = await navigator.mediaDevices.getUserMedia(profileConstraints);
          const videoTrack = this.localStream.getVideoTracks()[0];
          if (videoTrack) {
            const settings = videoTrack.getSettings();
            console.log(`‚úÖ [WebRTC] Video acquired: ${settings.width}x${settings.height}@${settings.frameRate}fps (${profile.label}) in ${Date.now() - startTime}ms`);
          }
          acquired = true;
        } catch (e) {
          console.log(`‚ö†Ô∏è [WebRTC] ${profile.label} failed, trying lower...`);
        }
      }
      
      // Final fallback: audio only or basic video
      if (!acquired) {
        if (this.isVideo) {
          try {
            this.localStream = await navigator.mediaDevices.getUserMedia({ 
              audio: audioConstraints, 
              video: true 
            });
            console.log(`‚úÖ [WebRTC] Basic video acquired in ${Date.now() - startTime}ms`);
          } catch (basicVideoError) {
            // Audio only fallback
            this.localStream = await navigator.mediaDevices.getUserMedia({ 
              audio: audioConstraints, 
              video: false 
            });
            console.log(`‚úÖ [WebRTC] Audio-only fallback in ${Date.now() - startTime}ms`);
          }
        } else {
          this.localStream = await navigator.mediaDevices.getUserMedia({ 
            audio: audioConstraints, 
            video: false 
          });
          console.log(`‚úÖ [WebRTC] Audio acquired in ${Date.now() - startTime}ms`);
        }
      }
      
      this.emit('localStream', this.localStream);
    } catch (error: any) {
      console.error('‚ùå [WebRTC] Media failed:', error.name, error.message);
      
      // Try audio-only fallback for video calls
      if (this.isVideo && error.name !== 'NotAllowedError') {
        try {
          console.log('‚ö†Ô∏è [WebRTC] Trying audio-only fallback...');
          this.localStream = await navigator.mediaDevices.getUserMedia({ 
            audio: { 
              echoCancellation: true, 
              noiseSuppression: true, 
              autoGainControl: true,
              // @ts-ignore
              googNoiseSuppression: true,
              // @ts-ignore
              googHighpassFilter: true,
            },
            video: false 
          });
          this.emit('localStream', this.localStream);
          return;
        } catch (fallbackError) {
          console.error('‚ùå [WebRTC] Audio fallback failed:', fallbackError);
        }
      }
      
      throw error;
    }
  }

  private async createPeerConnection() {
    // Detect Android WebView
    const isAndroid = typeof navigator !== 'undefined' && 
      /Android/i.test(navigator.userAgent);
    
    // ULTRA-FAST: Minimal ICE config for <2s connections
    const config: RTCConfiguration = {
      iceServers: [
        // STUN only - fastest for direct P2P (works 80%+ of the time)
        { urls: 'stun:stun.l.google.com:19302' },
        { urls: 'stun:stun1.l.google.com:19302' },
        // Single TURN for NAT traversal fallback
        {
          urls: 'turn:openrelay.metered.ca:443',
          username: 'openrelayproject',
          credential: 'openrelayproject'
        }
      ],
      iceTransportPolicy: 'all',
      bundlePolicy: 'max-bundle',
      rtcpMuxPolicy: 'require',
      iceCandidatePoolSize: 2, // Minimal pre-gathering
    };

    console.log(`üîß [WebRTC] Creating FAST peer connection (Android: ${isAndroid})`);
    this.pc = new RTCPeerConnection(config);
    
    // ANDROID FIX: Force VP8 codec for better Android WebView compatibility
    if (isAndroid && this.isVideo) {
      this.forceVP8Codec();
    }

    // Handle remote tracks - CRITICAL for bidirectional video
    this.pc.ontrack = (event) => {
      const track = event.track;
      const [remoteStream] = event.streams;
      console.log(`üì∫ [WebRTC] Remote track received: ${track.kind}, id: ${track.id.slice(0,8)}, stream tracks: ${remoteStream.getTracks().length}`);
      
      // Emit stream for EVERY track to ensure UI updates for both audio AND video
      this.emit('remoteStream', remoteStream);
      
      // Log track details for debugging bidirectional video
      if (track.kind === 'video') {
        console.log(`üìπ [WebRTC] VIDEO track settings:`, track.getSettings());
      }
    };

    // Handle ICE candidates - CRITICAL for connection establishment
    this.pc.onicecandidate = (event) => {
      if (event.candidate) {
        const candidateType = event.candidate.type || 'unknown';
        console.log(`üßä [WebRTC] ICE candidate: ${candidateType} (${event.candidate.protocol || 'udp'})`);
        this.sendSignal({ type: 'ice-candidate', data: event.candidate.toJSON(), from: this.userId });
      } else {
        console.log('‚úÖ [WebRTC] ICE gathering complete');
      }
    };

    // Track ICE gathering state for debugging
    this.pc.onicegatheringstatechange = () => {
      console.log(`üßä [WebRTC] ICE gathering state: ${this.pc?.iceGatheringState}`);
    };

    // Connection state changes
    this.pc.onconnectionstatechange = () => {
      const state = this.pc!.connectionState;
      console.log('üîå [WebRTC] Connection state:', state);
      
      if (state === 'connected') {
        this.handleConnected();
      } else if (state === 'failed') {
        this.handleConnectionFailed();
      } else if (state === 'closed') {
        if (this.callState === 'connected') {
          this.emit('ended');
        }
      }
    };

    // India-first: Use ICE monitor with extended tolerance
    const toleranceMs = this.callPreset?.iceDisconnectToleranceMs || 8000;
    const maxAttempts = this.callPreset?.maxReconnectAttempts || 3;
    
    this.iceMonitor = createICEMonitor(this.pc, {
      disconnectToleranceMs: toleranceMs,
      maxReconnectAttempts: maxAttempts,
      onRecoveryStart: () => {
        this.emit('recoveryStatus', { message: 'Reconnecting...' });
      },
      onRecoverySuccess: () => {
        console.log('‚úÖ [WebRTC] Recovery successful');
        this.emit('recoveryStatus', { message: null });
      },
      onRecoveryFailed: () => {
        console.log('‚ùå [WebRTC] Recovery failed after max attempts');
        this.handleConnectionFailed();
      },
      onQualityChange: (quality) => {
        this.emit('networkQuality', quality);
      }
    });

    // ICE connection state (backup handler)
    this.pc.oniceconnectionstatechange = () => {
      const state = this.pc!.iceConnectionState;
      console.log('‚ùÑÔ∏è [WebRTC] ICE state:', state);
      
      if (state === 'connected' || state === 'completed') {
        this.handleConnected();
      } else if (state === 'failed') {
        this.handleConnectionFailed();
      }
      // Note: 'disconnected' is now handled by ICE monitor with tolerance
    };

    console.log(`‚úÖ [WebRTC] Peer connection created with ${toleranceMs}ms disconnect tolerance`);
  }

  private handleConnected() {
    if (this.callState === 'connected') return;
    
    console.log(`üéâ [WebRTC] CONNECTED! [${this.instanceId}]`);
    this.callState = 'connected';
    this.clearConnectionTimeout();
    this.emit('connected');
    this.emit('networkQuality', 'good');
    
    // CRITICAL: Update call status to 'active' in database
    // This ensures UI and native shells know the call is truly connected
    this.updateCallToActive();
    
    // ADAPTIVE VIDEO: Apply stable bitrate for all bandwidth conditions (10kbps - 2Gbps)
    if (this.pc && this.isVideo) {
      this.applyAdaptiveVideoBitrate();
    }
    
    // India-first: Apply bitrate limits based on preset (only for hostile networks)
    if (this.pc && this.callPreset && this.networkQuality === 'HOSTILE') {
      applyBitrateLimits(this.pc, this.callPreset).then(() => {
        console.log(`üáÆüá≥ [WebRTC] Applied ${this.callPreset?.name} bitrate limits`);
      }).catch(e => {
        console.warn('‚ö†Ô∏è [WebRTC] Failed to apply bitrate limits:', e);
      });
    }
  }
  
  /**
   * Apply ADAPTIVE video bitrate for stability from 10kbps to 2Gbps
   * Priority: STABILITY over quality - smooth video at any bandwidth
   */
  private async applyAdaptiveVideoBitrate() {
    if (!this.pc) return;
    
    try {
      const videoSender = this.pc.getSenders().find(s => s.track?.kind === 'video');
      if (!videoSender) return;
      
      const params = videoSender.getParameters();
      if (!params.encodings || params.encodings.length === 0) {
        params.encodings = [{}];
      }
      
      // STABILITY-FIRST: Configure for adaptive bitrate with wide range
      // Allow browser to dynamically adjust between 10kbps and 25Mbps based on network
      params.encodings[0].maxBitrate = 25_000_000; // 25 Mbps maximum for 4K
      params.encodings[0].maxFramerate = 60;
      
      // @ts-ignore - scaleResolutionDownBy allows dynamic scaling
      params.encodings[0].scaleResolutionDownBy = 1; // Start at full resolution
      
      // @ts-ignore - Priority hints for stability
      params.encodings[0].priority = 'high';
      // @ts-ignore
      params.encodings[0].networkPriority = 'high';
      
      // Enable degradation preference for maintaining framerate over resolution
      // This keeps video smooth even on poor networks
      const track = videoSender.track;
      if (track) {
        try {
          await track.applyConstraints({
            // @ts-ignore - degradationPreference is experimental
            degradationPreference: 'maintain-framerate',
          });
        } catch (e) {
          // Ignore if not supported
        }
      }
      
      await videoSender.setParameters(params);
      console.log('üé¨ [WebRTC] Applied ADAPTIVE bitrate: 10kbps-25Mbps (stability-first)');
      
      // Start continuous quality monitoring for adaptive adjustment
      this.startAdaptiveBitrateMonitor();
    } catch (e) {
      console.warn('‚ö†Ô∏è [WebRTC] Could not apply adaptive bitrate:', e);
    }
  }
  
  private adaptiveMonitorInterval: NodeJS.Timeout | null = null;
  
  /**
   * Monitor connection quality and adapt bitrate for stability
   */
  private startAdaptiveBitrateMonitor() {
    // Clear existing monitor
    if (this.adaptiveMonitorInterval) {
      clearInterval(this.adaptiveMonitorInterval);
    }
    
    let lastBytesReceived = 0;
    let lastTimestamp = Date.now();
    
    this.adaptiveMonitorInterval = setInterval(async () => {
      if (!this.pc || this.callState !== 'connected') {
        if (this.adaptiveMonitorInterval) {
          clearInterval(this.adaptiveMonitorInterval);
          this.adaptiveMonitorInterval = null;
        }
        return;
      }
      
      try {
        const stats = await this.pc.getStats();
        let packetLoss = 0;
        let rtt = 0;
        let currentBitrate = 0;
        
        stats.forEach(report => {
          if (report.type === 'outbound-rtp' && report.kind === 'video') {
            const packetsLost = report.packetsLost || 0;
            const packetsSent = report.packetsSent || 0;
            packetLoss = packetsSent > 0 ? (packetsLost / packetsSent) * 100 : 0;
            
            // Calculate current outbound bitrate
            if (report.bytesSent && report.timestamp) {
              const now = Date.now();
              const bytesDelta = report.bytesSent - lastBytesReceived;
              const timeDelta = (now - lastTimestamp) / 1000;
              if (timeDelta > 0) {
                currentBitrate = (bytesDelta * 8) / timeDelta / 1000; // kbps
              }
              lastBytesReceived = report.bytesSent;
              lastTimestamp = now;
            }
          }
          
          if (report.type === 'candidate-pair' && report.state === 'succeeded') {
            rtt = (report.currentRoundTripTime || 0) * 1000;
          }
        });
        
        // Emit quality for UI updates (without noisy logs)
        if (packetLoss > 10 || rtt > 500) {
          this.emit('networkQuality', 'poor');
        } else if (packetLoss > 3 || rtt > 200) {
          this.emit('networkQuality', 'good');
        } else {
          this.emit('networkQuality', 'excellent');
        }
      } catch (e) {
        // Ignore stats errors
      }
    }, 3000); // Check every 3 seconds
  }
  
  private async updateCallToActive() {
    try {
      const { error } = await supabase
        .from('calls')
        .update({ 
          status: 'active', 
          webrtc_state: 'connected',
          started_at: new Date().toISOString()
        })
        .eq('id', this.callId);
      
      if (error) {
        console.warn('‚ö†Ô∏è [WebRTC] Failed to update call to active:', error);
      } else {
        console.log('‚úÖ [WebRTC] Call status updated to active');
      }
    } catch (e) {
      console.warn('‚ö†Ô∏è [WebRTC] Error updating call status:', e);
    }
  }

  private handleConnectionFailed() {
    if (this.callState === 'ended') return;
    
    console.warn('‚ö†Ô∏è [WebRTC] Connection failed - attempting recovery...');
    
    // Try ICE restart if we have remote description
    if (this.pc?.remoteDescription && this.isInitiator) {
      this.attemptIceRestart();
    } else {
      this.emit('recoveryStatus', { message: 'Reconnecting...' });
    }
  }

  private async attemptIceRestart() {
    if (!this.pc || this.callState === 'ended') return;
    
    try {
      console.log('üîÑ [WebRTC] ICE restart...');
      const offer = await this.pc.createOffer({ iceRestart: true });
      await this.pc.setLocalDescription(offer);
      await this.sendSignal({ type: 'offer', data: offer, from: this.userId });
    } catch (e) {
      console.error('‚ùå [WebRTC] ICE restart failed:', e);
    }
  }

  /**
   * India-first: Handle network quality changes during call
   */
  private handleNetworkChange(newQuality: NetworkQuality) {
    const oldQuality = this.networkQuality;
    this.networkQuality = newQuality;
    
    // Only adapt if quality degraded
    if (newQuality === 'HOSTILE' && oldQuality !== 'HOSTILE') {
      console.log('üì∂ [WebRTC] Network degraded to HOSTILE - reducing quality');
      this.emit('networkQuality', 'poor');
      
      // Apply bitrate limits if connected
      if (this.pc && this.callState === 'connected' && this.callPreset) {
        const survivalPreset = getCallPreset('HOSTILE', false);
        applyBitrateLimits(this.pc, survivalPreset).catch(e => 
          console.warn('‚ö†Ô∏è [WebRTC] Failed to apply bitrate limits:', e)
        );
      }
    } else if (newQuality === 'GOOD' && oldQuality !== 'GOOD') {
      console.log('üì∂ [WebRTC] Network improved to GOOD');
      this.emit('networkQuality', 'excellent');
    }
  }

  /**
   * Force VP8 codec for Android WebView compatibility
   * VP9 can cause frozen video on some Android devices
   */
  private forceVP8Codec() {
    if (!this.pc) return;
    
    const transceivers = this.pc.getTransceivers();
    transceivers.forEach(transceiver => {
      if (transceiver.sender.track?.kind === 'video' || transceiver.receiver.track?.kind === 'video') {
        const codecs = RTCRtpReceiver.getCapabilities?.('video')?.codecs || [];
        
        // Prioritize VP8 over VP9 for Android compatibility
        const vp8Codecs = codecs.filter(c => c.mimeType.toLowerCase().includes('vp8'));
        const h264Codecs = codecs.filter(c => c.mimeType.toLowerCase().includes('h264'));
        const otherCodecs = codecs.filter(c => 
          !c.mimeType.toLowerCase().includes('vp8') && 
          !c.mimeType.toLowerCase().includes('h264') &&
          !c.mimeType.toLowerCase().includes('vp9')
        );
        const vp9Codecs = codecs.filter(c => c.mimeType.toLowerCase().includes('vp9'));
        
        // Order: VP8 (most compatible) -> H264 -> VP9 (can cause issues)
        const orderedCodecs = [...vp8Codecs, ...h264Codecs, ...otherCodecs, ...vp9Codecs];
        
        if (orderedCodecs.length > 0 && transceiver.setCodecPreferences) {
          try {
            transceiver.setCodecPreferences(orderedCodecs);
            console.log('üé¨ [WebRTC] Forced VP8 codec priority for Android');
          } catch (e) {
            console.warn('‚ö†Ô∏è [WebRTC] Could not set codec preferences:', e);
          }
        }
      }
    });
  }

  private async fetchPastSignals() {
    console.log('üì• [WebRTC] Fetching past signals...');
    
    try {
      const { data: signals } = await supabase
        .from('webrtc_signals')
        .select('*')
        .eq('call_id', this.callId)
        .eq('to_user', this.userId)
        .order('created_at', { ascending: false }); // Get NEWEST first

      if (signals?.length) {
        console.log(`üì• [WebRTC] Found ${signals.length} past signals`);
        
        // Mark all as processed to prevent duplicates
        signals.forEach(s => this.processedSignalIds.add(s.id));
        
        if (!this.isInitiator) {
          // RECEIVER: Process ONLY the LATEST offer
          const latestOffer = signals.find(s => s.signal_type === 'offer');
          if (latestOffer) {
            console.log(`üì• [WebRTC] Processing LATEST offer from ${latestOffer.from_user.slice(0, 8)}`);
            await this.handleSignal({ type: 'offer', data: latestOffer.signal_data, from: latestOffer.from_user });
          }
        } else {
          // INITIATOR: Check if receiver already sent an answer
          const latestAnswer = signals.find(s => s.signal_type === 'answer');
          if (latestAnswer) {
            console.log(`üì• [WebRTC] Found answer from ${latestAnswer.from_user.slice(0, 8)}`);
            await this.handleSignal({ type: 'answer', data: latestAnswer.signal_data, from: latestAnswer.from_user });
          }
        }
        
        // Process ICE candidates for both roles (in ascending order for proper sequencing)
        const candidates = signals
          .filter(s => s.signal_type === 'ice-candidate')
          .reverse(); // Reverse to process oldest first
          
        for (const c of candidates) {
          await this.handleSignal({ type: 'ice-candidate', data: c.signal_data, from: c.from_user });
        }
      }
    } catch (error) {
      console.error('‚ùå [WebRTC] Failed to fetch past signals:', error);
    }
  }

  private async subscribeToSignals() {
    console.log('üì° [WebRTC] Subscribing to signals...');
    
    this.signalChannel = supabase
      .channel(`webrtc-${this.callId}-${this.userId}`)
      .on(
        'postgres_changes',
        {
          event: 'INSERT',
          schema: 'public',
          table: 'webrtc_signals',
          filter: `call_id=eq.${this.callId}`
        },
        (payload) => {
          const signal = payload.new as any;
          if (signal.to_user === this.userId) {
            // DEDUPE: Skip already processed signals
            if (this.processedSignalIds.has(signal.id)) {
              console.log('‚è≠Ô∏è [WebRTC] Skipping duplicate signal:', signal.id.slice(0, 8));
              return;
            }
            this.processedSignalIds.add(signal.id);
            
            console.log('üì• [WebRTC] Signal received:', signal.signal_type);
            this.handleSignal({
              type: signal.signal_type,
              data: signal.signal_data,
              from: signal.from_user
            });
          }
        }
      )
      .subscribe();
  }

  private async handleSignal(signal: Signal) {
    if (!this.pc) {
      console.error('‚ùå [WebRTC] No peer connection');
      return;
    }

    try {
      switch (signal.type) {
        case 'offer':
          // For initial offers: initiators ignore (they send offers)
          // For renegotiation: ALLOW if call is already connected (e.g., adding video)
          const isRenegotiation = this.callState === 'connected';
          
          if (this.isInitiator && !isRenegotiation) {
            console.log('‚è≠Ô∏è [WebRTC] Ignoring initial offer (I am initiator)');
            return;
          }
          
          console.log(`üì• [WebRTC] Processing ${isRenegotiation ? 'RENEGOTIATION' : 'INITIAL'} OFFER...`);
          await this.pc.setRemoteDescription(new RTCSessionDescription(signal.data));

          // FaceTime-style auto video upgrade:
          // If partner renegotiates specifically for video upgrade, auto-enable OUR camera too
          const upgradeReason = (signal.data as any)?.__chatr?.reason;
          if (isRenegotiation && upgradeReason === 'video-upgrade') {
            try {
              const hasLocalVideo = (this.localStream?.getVideoTracks()?.length || 0) > 0;
              if (!hasLocalVideo) {
                console.log('üìπ [WebRTC] Auto-enabling local video for bidirectional upgrade...');
                // No renegotiation here; we are responding with an answer.
                await this.enableLocalVideoAfterAccept();
              }
            } catch (e) {
              console.warn('‚ö†Ô∏è [WebRTC] Could not auto-enable local video:', e);
            }
          }
          
          // Always send answer for offers (including renegotiation)
          const answer = await this.pc.createAnswer();
          await this.pc.setLocalDescription(answer);
          await this.sendSignal({ type: 'answer', data: answer, from: this.userId });
          console.log('‚úÖ [WebRTC] ANSWER sent');
          this.answerSent = true;
          
          // Process queued ICE candidates
          await this.flushPendingCandidates();
          
          // Emit event so UI knows video was added
          if (isRenegotiation) {
            this.emit('renegotiationComplete');
          }
          break;

        case 'answer':
          // Process answers for this side
          // During renegotiation, both sides can receive answers
          if (!this.offerSent && !this.hasReceivedAnswer) {
            console.log('‚è≠Ô∏è [WebRTC] Ignoring unsolicited answer');
            return;
          }
          
          console.log('üì• [WebRTC] Processing ANSWER...');
          this.hasReceivedAnswer = true;
          await this.pc.setRemoteDescription(new RTCSessionDescription(signal.data));
          console.log('‚úÖ [WebRTC] ANSWER processed');
          
          // Process queued ICE candidates
          await this.flushPendingCandidates();
          break;

        case 'ice-candidate':
          if (this.pc.remoteDescription) {
            await this.pc.addIceCandidate(new RTCIceCandidate(signal.data));
          } else {
            this.pendingIceCandidates.push(new RTCIceCandidate(signal.data));
          }
          break;
          
        case 'video-request':
          console.log('üìπ [WebRTC] Video upgrade request received');
          this.emit('videoUpgradeRequest', signal.from);
          break;
          
        case 'video-accept':
          console.log('üìπ [WebRTC] Video upgrade accepted by partner');
          this.emit('videoUpgradeAccepted', signal.from);
          break;
          
        case 'video-reject':
          console.log('üìπ [WebRTC] Video upgrade rejected by partner');
          this.emit('videoUpgradeRejected', signal.from);
          break;

        case 'video-enable':
          console.log('üìπ [WebRTC] Video enable requested by partner');
          this.emit('videoEnableRequested', signal.from);
          break;
      }
    } catch (error) {
      console.error(`‚ùå [WebRTC] Signal error (${signal.type}):`, error);
    }
  }

  private async flushPendingCandidates() {
    if (this.pendingIceCandidates.length === 0) return;
    
    console.log(`üì• [WebRTC] Flushing ${this.pendingIceCandidates.length} queued candidates`);
    for (const candidate of this.pendingIceCandidates) {
      try {
        await this.pc?.addIceCandidate(candidate);
      } catch (e) {
        console.warn('‚ö†Ô∏è [WebRTC] Failed to add queued candidate:', e);
      }
    }
    this.pendingIceCandidates = [];
  }

  private async createAndSendOffer() {
    if (!this.pc || this.offerSent) return;

    try {
      console.log('üì§ [WebRTC] Creating offer...');
      this.offerSent = true;
      
      const offer = await this.pc.createOffer();
      await this.pc.setLocalDescription(offer);
      await this.sendSignal({ type: 'offer', data: offer, from: this.userId });
      console.log('‚úÖ [WebRTC] Offer sent');
    } catch (error) {
      console.error('‚ùå [WebRTC] Failed to create offer:', error);
      this.offerSent = false;
      throw error;
    }
  }

  private async sendSignal(signal: Signal) {
    const startTime = Date.now();
    try {
      // FAST: Don't wait for select - fire and forget for speed
      const { error } = await supabase.from('webrtc_signals').insert({
        call_id: this.callId,
        signal_type: signal.type,
        signal_data: signal.data,
        from_user: this.userId,
        to_user: this.partnerId
      });
      
      if (error) {
        console.error(`‚ùå [WebRTC] Signal send failed (${signal.type}):`, error.message);
        throw error;
      }
      
      console.log(`üì§ [WebRTC] Signal sent: ${signal.type} (${Date.now() - startTime}ms)`);
    } catch (error: any) {
      console.error(`‚ùå [WebRTC] Failed to send ${signal.type}:`, error?.message || error);
    }
  }

  private startConnectionTimeout() {
    // 15 seconds for initial connection (fast failure feedback)
    this.connectionTimeout = setTimeout(() => {
      if (this.callState === 'connecting') {
        console.warn('‚è∞ [WebRTC] Connection timeout after 15s');
        
        if (!this.hasReceivedAnswer && this.isInitiator) {
          // No answer received - partner may not have answered yet
          console.log('‚è≥ [WebRTC] No answer yet, waiting...');
          this.emit('recoveryStatus', { message: 'Waiting for answer...' });
          // Extend timeout for another 15s
          this.connectionTimeout = setTimeout(() => {
            if (this.callState === 'connecting') {
              console.error('‚ùå [WebRTC] Connection failed - no answer');
              this.callState = 'failed';
              this.emit('failed', new Error('No answer received'));
            }
          }, 15000);
        } else {
          // Have answer but still not connected - ICE issue
          console.log('üîÑ [WebRTC] ICE stalled, restarting...');
          this.emit('recoveryStatus', { message: 'Reconnecting...' });
          this.pc?.restartIce();
          // Give 10 more seconds after restart
          this.connectionTimeout = setTimeout(() => {
            if (this.callState === 'connecting') {
              console.error('‚ùå [WebRTC] Connection failed after ICE restart');
              this.callState = 'failed';
              this.emit('failed', new Error('ICE connection failed'));
            }
          }, 10000);
        }
      }
    }, 15000);
  }

  private clearConnectionTimeout() {
    if (this.connectionTimeout) {
      clearTimeout(this.connectionTimeout);
      this.connectionTimeout = null;
    }
  }

  toggleAudio(enabled: boolean) {
    this.localStream?.getAudioTracks().forEach(track => {
      track.enabled = enabled;
    });
  }

  toggleVideo(enabled: boolean) {
    this.localStream?.getVideoTracks().forEach(track => {
      track.enabled = enabled;
    });
  }

  // ============== VIDEO UPGRADE (FACE TIME AUTO) ==============
  
  /**
   * Ask partner to auto-enable video (no consent modal)
   * Used when the non-initiator clicks video; initiator will renegotiate.
   */
  async sendVideoEnable(): Promise<void> {
    console.log('üìπ [WebRTC] Sending video enable signal...');
    await this.sendSignal({
      type: 'video-enable',
      data: { timestamp: Date.now() },
      from: this.userId,
    });
  }

  // ==============================================================
  /**
   * Accept video upgrade request and enable local video
   * The ACCEPTOR is the one who triggers renegotiation to prevent glare
   */
  async acceptVideoUpgrade(): Promise<MediaStream | null> {
    console.log('üìπ [WebRTC] Accepting video upgrade - I will trigger renegotiation...');
    
    // First enable our own video and trigger renegotiation
    const stream = await this.addVideoToCall();
    
    // THEN notify partner we accepted (they will just add local video without renegotiating)
    await this.sendSignal({ 
      type: 'video-accept', 
      data: { timestamp: Date.now() }, 
      from: this.userId 
    });
    
    return stream;
  }

  /**
   * Enable local video for the requester AFTER partner accepted
   * Does NOT trigger renegotiation - just adds local video track
   * The acceptor's renegotiation will handle adding our track to their view
   */
  async enableLocalVideoAfterAccept(): Promise<MediaStream | null> {
    if (!this.pc) {
      console.error('‚ùå [WebRTC] No peer connection for video');
      return null;
    }

    try {
      console.log('üìπ [WebRTC] Enabling local video (no renegotiation - acceptor handles it)...');
      
      // Request video
      let videoStream: MediaStream;
      try {
        videoStream = await navigator.mediaDevices.getUserMedia({
          video: { 
            width: { ideal: 1280, max: 1920 }, 
            height: { ideal: 720, max: 1080 }, 
            frameRate: { ideal: 30 },
            facingMode: 'user',
          }
        });
        console.log('‚úÖ [WebRTC] Video acquired for requester');
      } catch (e: any) {
        console.log('‚ö†Ô∏è [WebRTC] HD failed, using basic video...');
        videoStream = await navigator.mediaDevices.getUserMedia({ video: true });
      }

      const videoTrack = videoStream.getVideoTracks()[0];
      if (!videoTrack) {
        console.error('‚ùå [WebRTC] No video track obtained');
        return null;
      }
      
      console.log('üìπ [WebRTC] Got video track:', videoTrack.label);
      
      // Check if we already have a video sender from the current peer connection
      const existingVideoSender = this.pc.getSenders().find(s => s.track?.kind === 'video');
      
      if (existingVideoSender) {
        // Just replace the track - no renegotiation from this helper
        await existingVideoSender.replaceTrack(videoTrack);
        console.log('üìπ [WebRTC] Replaced video sender track (no renegotiation)');
      } else {
        // Add track; the current/next offer-answer will carry it
        console.log('üìπ [WebRTC] No existing sender - adding video track (no renegotiation)');
        const stream = this.localStream || new MediaStream([videoTrack]);
        this.pc.addTrack(videoTrack, stream);
      }
      
      // Update local stream for UI
      if (this.localStream) {
        const oldVideoTrack = this.localStream.getVideoTracks()[0];
        if (oldVideoTrack && oldVideoTrack !== videoTrack) {
          this.localStream.removeTrack(oldVideoTrack);
          oldVideoTrack.stop();
        }
        if (!this.localStream.getVideoTracks().includes(videoTrack)) {
          this.localStream.addTrack(videoTrack);
        }
      } else {
        this.localStream = videoStream;
      }
      
      this.emit('localStream', this.localStream);
      return this.localStream;
    } catch (error) {
      console.error('‚ùå [WebRTC] Failed to enable local video:', error);
      return null;
    }
  }

  /**
   * Reject video upgrade request
   */
  async rejectVideoUpgrade(): Promise<void> {
    console.log('üìπ [WebRTC] Rejecting video upgrade...');
    await this.sendSignal({ 
      type: 'video-reject', 
      data: { timestamp: Date.now() }, 
      from: this.userId 
    });
  }
  
  // ==============================================================

  async addVideoToCall(): Promise<MediaStream | null> {
    if (!this.pc) {
      console.error('‚ùå [WebRTC] No peer connection for video');
      return null;
    }

    try {
      console.log('üìπ [WebRTC] Adding HD video to call (FaceTime-style)...');
      
      // Request HD video with progressive fallback
      let videoStream: MediaStream;
      try {
        // Try 1080p HD first
        videoStream = await navigator.mediaDevices.getUserMedia({
          video: { 
            width: { ideal: 1920, min: 1280, max: 1920 }, 
            height: { ideal: 1080, min: 720, max: 1080 }, 
            frameRate: { ideal: 30, min: 24, max: 60 },
            facingMode: 'user',
            aspectRatio: { ideal: 16/9 },
          }
        });
        console.log('‚úÖ [WebRTC] 1080p HD video acquired');
      } catch (hdError: any) {
        console.log('‚ö†Ô∏è [WebRTC] 1080p failed, trying 720p...');
        try {
          // Fallback to 720p
          videoStream = await navigator.mediaDevices.getUserMedia({
            video: { 
              width: { ideal: 1280, max: 1280 }, 
              height: { ideal: 720, max: 720 }, 
              frameRate: { ideal: 30 },
              facingMode: 'user' 
            }
          });
          console.log('‚úÖ [WebRTC] 720p video acquired');
        } catch (sdError: any) {
          console.log('‚ö†Ô∏è [WebRTC] 720p failed, using basic video...');
          videoStream = await navigator.mediaDevices.getUserMedia({ video: true });
        }
      }

      const videoTrack = videoStream.getVideoTracks()[0];
      if (!videoTrack) {
        console.error('‚ùå [WebRTC] No video track obtained');
        return null;
      }
      
      console.log('üìπ [WebRTC] Got video track:', videoTrack.label);
      
      // Check if we already have a video sender
      const existingVideoSender = this.pc.getSenders().find(s => s.track?.kind === 'video');
      
      if (existingVideoSender) {
        await existingVideoSender.replaceTrack(videoTrack);
        console.log('üìπ [WebRTC] Replaced existing video track');
      } else {
        // Add new video track to connection
        const stream = this.localStream || new MediaStream([videoTrack]);
        this.pc.addTrack(videoTrack, stream);
        console.log('üìπ [WebRTC] Added new video track to peer connection');
      }
      
      // Update local stream for UI
      if (this.localStream) {
        const oldVideoTrack = this.localStream.getVideoTracks()[0];
        if (oldVideoTrack) {
          this.localStream.removeTrack(oldVideoTrack);
          oldVideoTrack.stop();
        }
        this.localStream.addTrack(videoTrack);
      } else {
        this.localStream = videoStream;
      }
      
      this.emit('localStream', this.localStream);

      // Renegotiate to inform partner (tagged so receiver can auto-enable their camera too)
      this.hasReceivedAnswer = false;
      this.offerSent = false;
      
      const offer = await this.pc.createOffer();
      (offer as any).__chatr = { reason: 'video-upgrade' };
      await this.pc.setLocalDescription(offer);
      await this.sendSignal({ type: 'offer', data: offer, from: this.userId });
      console.log('üì§ [WebRTC] Sent renegotiation offer with video');

      return this.localStream;
    } catch (error) {
      console.error('‚ùå [WebRTC] Failed to add video:', error);
      return null;
    }
  }

  sendDTMF(digit: string) {
    const sender = this.pc?.getSenders().find(s => s.track?.kind === 'audio');
    if (sender?.dtmf) {
      sender.dtmf.insertDTMF(digit, 100, 70);
    }
  }

  // Track current camera facing mode
  private currentFacingMode: 'user' | 'environment' = 'user';
  private isSwitchingCamera: boolean = false;

  async switchCamera(): Promise<'user' | 'environment'> {
    // Prevent multiple simultaneous switch attempts (causes stuck camera)
    if (this.isSwitchingCamera) {
      console.log('‚è≥ [WebRTC] Camera switch in progress, ignoring...');
      return this.currentFacingMode;
    }
    
    const videoTrack = this.localStream?.getVideoTracks()[0];
    if (!videoTrack) throw new Error('No video track');

    this.isSwitchingCamera = true;
    
    // Determine new facing mode
    const newFacing = this.currentFacingMode === 'user' ? 'environment' : 'user';
    console.log(`üì∑ [WebRTC] Switching camera: ${this.currentFacingMode} ‚Üí ${newFacing}`);

    // Progressive camera acquisition with multiple fallbacks
    const cameraProfiles = [
      { facingMode: { exact: newFacing }, width: { ideal: 1920 }, height: { ideal: 1080 }, label: 'exact-1080p' },
      { facingMode: { exact: newFacing }, width: { ideal: 1280 }, height: { ideal: 720 }, label: 'exact-720p' },
      { facingMode: newFacing, width: { ideal: 1280 }, height: { ideal: 720 }, label: 'ideal-720p' },
      { facingMode: newFacing, width: { ideal: 640 }, height: { ideal: 480 }, label: 'ideal-480p' },
      { facingMode: newFacing, label: 'basic' },
    ];

    try {
      let newVideoTrack: MediaStreamTrack | null = null;
      
      for (const profile of cameraProfiles) {
        try {
          console.log(`üì∑ [WebRTC] Trying camera profile: ${profile.label}`);
          const newStream = await navigator.mediaDevices.getUserMedia({ video: profile });
          newVideoTrack = newStream.getVideoTracks()[0];
          if (newVideoTrack) {
            console.log(`‚úÖ [WebRTC] Camera acquired with profile: ${profile.label}`);
            break;
          }
        } catch (profileError) {
          console.log(`‚ö†Ô∏è [WebRTC] Profile ${profile.label} failed, trying next...`);
        }
      }

      if (!newVideoTrack) {
        throw new Error('All camera profiles failed');
      }

      // Replace track in peer connection with timeout
      const replacePromise = this.replaceTrack(newVideoTrack);
      const timeoutPromise = new Promise((_, reject) => 
        setTimeout(() => reject(new Error('Track replace timeout')), 5000)
      );
      
      await Promise.race([replacePromise, timeoutPromise]);

      // Stop old track AFTER successful replacement
      videoTrack.stop();
      
      // Update state
      this.currentFacingMode = newFacing;
      
      // Force re-emit localStream to update UI
      if (this.localStream) {
        // Create a fresh stream reference to force UI update
        const freshStream = new MediaStream(this.localStream.getTracks());
        this.localStream = freshStream;
        this.emit('localStream', this.localStream);
      }

      console.log(`‚úÖ [WebRTC] Camera switched to ${newFacing}`);
      return newFacing;
    } catch (e: any) {
      console.error('‚ùå [WebRTC] Switch camera failed completely:', e);
      // Don't throw - return current facing mode to prevent UI crash
      return this.currentFacingMode;
    } finally {
      // Always unlock
      this.isSwitchingCamera = false;
    }
  }

  async replaceTrack(newTrack: MediaStreamTrack): Promise<void> {
    const sender = this.pc?.getSenders().find(s => s.track?.kind === newTrack.kind);
    if (sender) {
      await sender.replaceTrack(newTrack);
      
      // Update local stream
      if (this.localStream) {
        const oldTrack = this.localStream.getTracks().find(t => t.kind === newTrack.kind);
        if (oldTrack) {
          this.localStream.removeTrack(oldTrack);
        }
        this.localStream.addTrack(newTrack);
      }
    }
  }

  applyZoom(scale: number) {
    const videoTrack = this.localStream?.getVideoTracks()[0];
    if (!videoTrack) return;

    try {
      const capabilities = videoTrack.getCapabilities?.() as any;
      if (capabilities?.zoom) {
        const constraints = { advanced: [{ zoom: scale } as any] };
        videoTrack.applyConstraints(constraints);
      }
    } catch (e) {
      console.warn('Zoom not supported on this device');
    }
  }

  /**
   * Get peer connection for external access (e.g., ultra-low bandwidth hooks)
   */
  getPeerConnection(): RTCPeerConnection | null {
    return this.pc;
  }

  async end() {
    console.log('üëã [WebRTC] Ending call...');
    this.callState = 'ended';
    this.clearConnectionTimeout();
    
    // Remove from active instances
    activeCallInstances.delete(this.callId);
    
    await this.cleanup();
    this.emit('ended');
  }

  private async cleanup() {
    // Stop local tracks
    this.localStream?.getTracks().forEach(t => t.stop());
    this.localStream = null;

    // Cleanup adaptive bitrate monitor
    if (this.adaptiveMonitorInterval) {
      clearInterval(this.adaptiveMonitorInterval);
      this.adaptiveMonitorInterval = null;
    }

    // Cleanup ICE monitor
    if (this.iceMonitor) {
      this.iceMonitor.cleanup();
      this.iceMonitor = null;
    }
    
    // Cleanup network change listener
    if (this.networkChangeCleanup) {
      this.networkChangeCleanup();
      this.networkChangeCleanup = null;
    }

    // Close peer connection
    if (this.pc) {
      this.pc.onconnectionstatechange = null;
      this.pc.oniceconnectionstatechange = null;
      this.pc.ontrack = null;
      this.pc.onicecandidate = null;
      this.pc.close();
      this.pc = null;
    }

    // Unsubscribe from signals
    if (this.signalChannel) {
      await supabase.removeChannel(this.signalChannel);
      this.signalChannel = null;
    }
  }

  private delay(ms: number): Promise<void> {
    return new Promise(resolve => setTimeout(resolve, ms));
  }
}
